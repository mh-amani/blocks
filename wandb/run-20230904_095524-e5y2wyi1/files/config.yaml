wandb_version: 1

_wandb:
  desc: null
  value:
    python_version: 3.11.4
    cli_version: 0.15.8
    framework: huggingface
    huggingface_version: 4.32.0
    is_jupyter_run: false
    is_kaggle_kernel: false
    start_time: 1693814124.86255
    t:
      1:
      - 1
      - 5
      - 9
      - 11
      - 49
      - 50
      - 51
      - 53
      - 55
      - 103
      2:
      - 1
      - 5
      - 9
      - 11
      - 49
      - 50
      - 51
      - 53
      - 55
      - 103
      3:
      - 1
      - 7
      - 13
      - 23
      4: 3.11.4
      5: 0.15.8
      6: 4.32.0
      8:
      - 5
    m:
    - 1: trainer/global_step
      6:
      - 3
trainer:
  desc: null
  value: '{''_target_'': ''pytorch_lightning.Trainer'', ''devices'': ''auto'', ''accelerator'':
    ''auto'', ''accumulate_grad_batches'': 1, ''max_epochs'': 1000, ''min_epochs'':
    10, ''max_steps'': -1, ''check_val_every_n_epoch'': 1, ''fast_dev_run'': False}'
model:
  desc: null
  value: '{''discretizer'': {''entmax'': {''_target_'': ''src.models.modules.discrete_layers.entmax.EntmaxDiscreteLayer'',
    ''alpha'': 1.1}, ''gumbel'': {''_target_'': ''src.models.modules.discrete_layers.gumbel.Gumbel'',
    ''params'': None}}, ''collator'': {}, ''lr_scheduler'': {''_target_'': ''torch.optim.lr_scheduler.ReduceLROnPlateau'',
    ''mode'': ''min'', ''factor'': 0.8, ''patience'': 1, ''threshold'': 0.01, ''threshold_mode'':
    ''abs'', ''cooldown'': 1, ''min_lr'': 1e-06, ''eps'': 1e-08, ''verbose'': True,
    ''interval'': ''epoch'', ''frequency'': 1, ''monitor'': ''train/loss'', ''model_x_to_z_scheduler'':
    {''_target_'': ''${model.lr_scheduler._target_}'', ''mode'': ''${model.lr_scheduler.mode}'',
    ''factor'': ''${model.lr_scheduler.factor}'', ''patience'': ''${model.lr_scheduler.patience}'',
    ''threshold'': ''${model.lr_scheduler.threshold}'', ''threshold_mode'': ''${model.lr_scheduler.threshold_mode}'',
    ''cooldown'': ''${model.lr_scheduler.cooldown}'', ''min_lr'': ''${model.lr_scheduler.min_lr}'',
    ''eps'': ''${model.lr_scheduler.eps}'', ''verbose'': ''${model.lr_scheduler.verbose}''},
    ''model_x_to_z_scheduler_dict'': {''interval'': ''${model.lr_scheduler.interval}'',
    ''frequency'': ''${model.lr_scheduler.frequency}'', ''monitor'': ''${model.lr_scheduler.monitor}'',
    ''name'': ''LearningRateScheduler_${model.lr_scheduler.model_x_to_z_scheduler._target_}''},
    ''model_z_to_x_scheduler'': {''_target_'': ''${model.lr_scheduler._target_}'',
    ''mode'': ''${model.lr_scheduler.mode}'', ''factor'': ''${model.lr_scheduler.factor}'',
    ''patience'': ''${model.lr_scheduler.patience}'', ''threshold'': ''${model.lr_scheduler.threshold}'',
    ''threshold_mode'': ''${model.lr_scheduler.threshold_mode}'', ''cooldown'': ''${model.lr_scheduler.cooldown}'',
    ''min_lr'': ''${model.lr_scheduler.min_lr}'', ''eps'': ''${model.lr_scheduler.eps}'',
    ''verbose'': ''${model.lr_scheduler.verbose}''}, ''model_z_to_x_scheduler_dict'':
    {''interval'': ''${model.lr_scheduler.interval}'', ''frequency'': ''${model.lr_scheduler.frequency}'',
    ''monitor'': ''${model.lr_scheduler.monitor}'', ''name'': ''LearningRateScheduler_${model.lr_scheduler.model_z_to_x_scheduler._target_}''},
    ''disc_x_scheduler'': {''_target_'': ''${model.lr_scheduler._target_}'', ''mode'':
    ''${model.lr_scheduler.mode}'', ''factor'': ''${model.lr_scheduler.factor}'',
    ''patience'': ''${model.lr_scheduler.patience}'', ''threshold'': ''${model.lr_scheduler.threshold}'',
    ''threshold_mode'': ''${model.lr_scheduler.threshold_mode}'', ''cooldown'': ''${model.lr_scheduler.cooldown}'',
    ''min_lr'': ''${model.lr_scheduler.min_lr}'', ''eps'': ''${model.lr_scheduler.eps}'',
    ''verbose'': ''${model.lr_scheduler.verbose}''}, ''disc_x_scheduler_dict'': {''interval'':
    ''${model.lr_scheduler.interval}'', ''frequency'': ''${model.lr_scheduler.frequency}'',
    ''monitor'': ''${model.lr_scheduler.monitor}'', ''name'': ''LearningRateScheduler_${model.lr_scheduler.disc_x_scheduler._target_}''},
    ''disc_z_scheduler'': {''_target_'': ''${model.lr_scheduler._target_}'', ''mode'':
    ''${model.lr_scheduler.mode}'', ''factor'': ''${model.lr_scheduler.factor}'',
    ''patience'': ''${model.lr_scheduler.patience}'', ''threshold'': ''${model.lr_scheduler.threshold}'',
    ''threshold_mode'': ''${model.lr_scheduler.threshold_mode}'', ''cooldown'': ''${model.lr_scheduler.cooldown}'',
    ''min_lr'': ''${model.lr_scheduler.min_lr}'', ''eps'': ''${model.lr_scheduler.eps}'',
    ''verbose'': ''${model.lr_scheduler.verbose}''}, ''disc_z_scheduler_dict'': {''interval'':
    ''${model.lr_scheduler.interval}'', ''frequency'': ''${model.lr_scheduler.frequency}'',
    ''monitor'': ''${model.lr_scheduler.monitor}'', ''name'': ''LearningRateScheduler_${model.lr_scheduler.disc_z_scheduler._target_}''}},
    ''optimizer'': {''_target_'': ''torch.optim.AdamW'', ''lr'': 0.001, ''weight_decay'':
    0.01, ''eps'': 1e-08, ''betas'': [0.9, 0.999]}, ''sequence_to_sequence_model'':
    {''bert_bert'': {''_target_'': ''src.models.modules.sequence_to_sequence_models.encoder_decoder.EncoderDecoder'',
    ''config_encoder'': {''_target_'': ''transformers.models.bert.modeling_bert.BertConfig'',
    ''vocab_size'': 20, ''hidden_size'': 128, ''num_hidden_layers'': 2, ''num_attention_heads'':
    4, ''intermediate_size'': 512, ''max_position_embeddings'': 100, ''hidden_act'':
    ''gelu'', ''pad_token_id'': 0}, ''config_decoder'': {''_target_'': ''transformers.models.bert.modeling_bert.BertConfig'',
    ''vocab_size'': 20, ''hidden_size'': 128, ''num_hidden_layers'': 2, ''num_attention_heads'':
    4, ''intermediate_size'': 512, ''max_position_embeddings'': 100, ''hidden_act'':
    ''gelu'', ''pad_token_id'': 0}}, ''bert_gpt2'': {''_target_'': ''to be filled
    in'', ''params'': {''encoder_params'': ''to be filled in'', ''decoder_params'':
    ''to be filled in''}}}, ''_target_'': ''src.models.xz_autoencoder.XZAutoencoder'',
    ''name'': ''XZAutoencoder'', ''pad_token_id'': 0, ''bos_token_id'': 1, ''eos_token_id'':
    2, ''modules'': {''model_x_to_z'': ''${model.sequence_to_sequence_model.bert_bert}'',
    ''model_z_to_x'': ''${model.sequence_to_sequence_model.bert_bert}'', ''disc_x'':
    ''${model.discretizer.entmax}'', ''disc_z'': ''${model.discretizer.entmax}''},
    ''model_params'': {''reconstruction_loss_coeff_x'': 1.0, ''reconstruction_loss_coeff_z'':
    1.0}}'
datamodule:
  desc: null
  value: '{''tokenizer'': {''_target_'': ''src.datamodules.tokenizers.simple_unigram_tokenizer.SimpleUnigramTokenizer'',
    ''model_max_length'': 100, ''padding_side'': ''right'', ''vocab_size'': 15, ''show_progress'':
    True, ''special_tokens'': [''[pad]'', ''[bos]'', ''[eos]'', ''[UNK]''], ''batch_size'':
    ''${datamodule.batch_size}''}, ''_target_'': ''src.datamodules.scan.SCANDatamodule'',
    ''dataset_target_'': ''src.datamodules.scan.SCANDataset'', ''seed'': 42, ''p_sup'':
    ''callback.z_supervised_scheduler.scheduler.hp_init'', ''dataset_parameters'':
    {''seed'': ''${seed}'', ''batch_size'': 128, ''test_split'': ''simple'', ''train_ratio'':
    0.8, ''sup_ratio'': 0.1, ''num_workers'': 1, ''overfit_batch'': ''${overfit_batch}''},
    ''datasets'': {''seed'': ''${seed}'', ''test'': {''_target_'': ''${datamodule.dataset_target_}'',
    ''split'': ''test''}, ''train'': {''_target_'': ''${datamodule.dataset_target_}'',
    ''split'': ''train''}, ''val'': {''_target_'': ''${datamodule.dataset_target_}'',
    ''split'': ''val''}}, ''sup_ratio'': 0.02, ''batch_size'': 128, ''num_workers'':
    1}'
model/params_total:
  desc: null
  value: 2014504
model/params_trainable:
  desc: null
  value: 2014504
model/params_not_trainable:
  desc: null
  value: 0
rel_path_to_work_dir:
  desc: null
  value: .
seed:
  desc: null
  value: 42
callbacks:
  desc: null
  value: '{''model_checkpoint'': {''_target_'': ''pytorch_lightning.callbacks.ModelCheckpoint'',
    ''monitor'': ''val/loss'', ''mode'': ''min'', ''save_top_k'': 3, ''save_last'':
    True, ''verbose'': False, ''dirpath'': ''checkpoints/'', ''filename'': ''model-{step:04d}-{val/loss:.4f}'',
    ''save_on_train_epoch_end'': False, ''auto_insert_metric_name'': False}, ''learning_rate_monitor'':
    {''_target_'': ''pytorch_lightning.callbacks.LearningRateMonitor'', ''logging_interval'':
    ''step''}, ''early_stopping'': {''_target_'': ''pytorch_lightning.callbacks.EarlyStopping'',
    ''monitor'': ''val/loss'', ''mode'': ''min'', ''patience'': 200, ''min_delta'':
    0}, ''probability_logger_wandb'': {''_target_'': ''src.callbacks.wandb_output_logger.ProbabilityLogger''},
    ''z_supervised_scheduler'': {''_target_'': ''src.callbacks.scheduler_callback.SchedulerCallback'',
    ''hyperparameter_location'': ''trainer.datamodule.train_sampler.p_sup'', ''hyperparameter_location_pl'':
    ''model_params.prob_z_sup'', ''scheduler'': {''_target_'': ''src.schedulers.linear_scheduler.LinearScheduler'',
    ''num_warmup_steps'': 25, ''num_training_steps'': 80, ''hp_init'': 1.0, ''hp_end'':
    0.0, ''power'': 1.0}}}'
