_target_: src.models.xz_autoencoder.XZAutoencoder.load_from_checkpoint
checkpoint_path: ???

defaults:
  - collator: loaded_collator
  - lr_scheduler: reduce_on_plateau
  - optimizer: default

model_params:
    decode_after_autoreg_step: ${model.substitute_config.model_params.decode_after_autoreg_step}
    max_x_length: ${model.substitute_config.model_params.max_x_length}
    max_x_vocab_size: ${model.substitute_config.model_params.max_x_vocab_size}
    max_z_length: ${model.substitute_config.model_params.max_z_length}
    max_z_vocab_size: ${model.substitute_config.model_params.max_z_vocab_size}
    # max_x_length: 100 # 158 is the max length of a sentence in the dataset
    # max_x_vocab_size: 60 # 53
    # max_z_length: 250 # 2018 is the max length of a sentence in the dataset
    # max_z_vocab_size: 50 # 40

substitute_config:  
  collator: ${model.collator}

  model_params:
    decode_after_autoreg_step: True
    # max_x_length: 100
    # max_x_vocab_size: 200
    # max_z_length: 100
    # max_z_vocab_size: 200
    # max_x_length: 3
    # max_x_vocab_size: 7
    # max_z_length: 3
    # max_z_vocab_size: 7

    loss_coeff:
      xzx: 1.0
      zxz: 1.0
      supervised_seperated_x: 1.0
      supervised_seperated_z: 1.0
    
    acc_grad_batch: 1

    use_tokenizer_vocab_len: true
    disc_x_vocab_size: -1
    disc_z_vocab_size: -1

  optimizer:
    lr: 0.002232423

  lr_scheduler:
    mode: "min"
    factor: 0.8
    patience: 5
    threshold: 0.01
    threshold_mode: "abs"
    cooldown: 5
    min_lr: 1e-6
    eps: 1e-8
    verbose: True
  